{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN_res tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ogb\n",
    "!pip install torch_geometric\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, JumpingKnowledge\n",
    "from torch_geometric.data import NeighborSampler\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None, print_all=True):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            if print_all:\n",
    "                r = best_result[:, 0]\n",
    "                print(f'Highest Train: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "                r = best_result[:, 1]\n",
    "                print(f'Highest Valid: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "                r = best_result[:, 2]\n",
    "                print(f'  Final Train: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} Â± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./arxiv/', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "test_idx = split_idx['test']\n",
    "\n",
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_res(nn.Module):\n",
    "    def __init__(self, dataset, hidden=256, num_layers=6):\n",
    "        super(GCN_res, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        self.input_fc = nn.Linear(dataset.num_node_features, hidden)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(GCNConv(hidden, hidden))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden))\n",
    "\n",
    "        self.out_fc = nn.Linear(hidden, dataset.num_classes)\n",
    "        self.weights = torch.nn.Parameter(torch.randn((len(self.convs))))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        self.input_fc.reset_parameters()\n",
    "        self.out_fc.reset_parameters()\n",
    "        torch.nn.init.normal_(self.weights)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, adj_t = data.x, data.adj_t\n",
    "\n",
    "        x = self.input_fc(x)\n",
    "        x_input = x \n",
    "\n",
    "        layer_out = []\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x, inplace=True)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "            if i == 0:\n",
    "                x = x + 0.2 * x_input\n",
    "            else:\n",
    "                x = x + 0.2 * x_input + 0.5 * layer_out[i - 1]\n",
    "            layer_out.append(x)\n",
    "\n",
    "        weight = F.softmax(self.weights, dim=0)\n",
    "        for i in range(len(layer_out)):\n",
    "            layer_out[i] = layer_out[i] * weight[i]\n",
    "\n",
    "        x = sum(layer_out)\n",
    "        x = self.out_fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN_res(dataset=dataset, hidden=128, num_layers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "data = data.to(device)\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "train_idx = train_idx.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    out = model(data)\n",
    "    loss = criterion(out[train_idx], data.y.squeeze(1)[train_idx])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 2\n",
    "logger = Logger(runs)\n",
    "\n",
    "for run in range(runs):\n",
    "        print(sum(p.numel() for p in model.parameters()))\n",
    "        model.reset_parameters()\n",
    "\n",
    "        for epoch in range(500):\n",
    "            loss = train()\n",
    "\n",
    "            result = test()\n",
    "            train_acc, valid_acc, test_acc = result\n",
    "            print(f'Run: {run + 1:02d}, '\n",
    "                  f'Epoch: {epoch:02d}, '\n",
    "                  f'Loss: {loss:.4f}, '\n",
    "                  f'Train: {100 * train_acc:.2f}%, '\n",
    "                  f'Valid: {100 * valid_acc:.2f}% '\n",
    "                  f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "    logger.print_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
